{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WE5Tk71Za3qW"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QN7aaXkXuM1M"
   },
   "outputs": [],
   "source": [
    "!cd stargan-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCn-yHAWE5CT"
   },
   "outputs": [],
   "source": [
    "!conda activate stargan-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddyA3Njsy6v9"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIFWli6Ly9J0"
   },
   "outputs": [],
   "source": [
    "!python3 main.py --mode train --num_domains 3 --w_hpf 0 \\\n",
    "                --lambda_reg 1 --lambda_sty 1 --lambda_ds 2 --lambda_cyc 1 \\\n",
    "                --train_img_dir data/afhq/train \\\n",
    "                --val_img_dir data/afhq/val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL1ERemCzKYs"
   },
   "source": [
    "## Generate with my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --mode align \\\n",
    "                --inp_dir assets/representative/custom/cat \\\n",
    "                --out_dir assets/representative/afhq/src/cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NfAbJPs_zNR8",
    "outputId": "30485def-966d-4e7c-ed95-6c025f24812d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=8, beta1=0.0, beta2=0.99, checkpoint_dir='expr/checkpoints/afhq', ds_iter=100000, eval_dir='expr/eval', eval_every=50000, f_lr=1e-06, hidden_dim=512, img_size=256, inp_dir='assets/representative/custom/female', lambda_cyc=1, lambda_ds=1, lambda_reg=1, lambda_sty=1, latent_dim=16, lm_path='expr/checkpoints/celeba_lm_mean.npz', lr=0.0001, mode='sample', num_domains=3, num_outs_per_domain=10, num_workers=4, out_dir='assets/representative/celeba_hq/src/female', print_every=10, randcrop_prob=0.5, ref_dir='assets/representative/afhq/ref', result_dir='expr/results/afhq', resume_iter=100000, sample_dir='expr/samples', sample_every=5000, save_every=10000, seed=777, src_dir='assets/representative/afhq/src', style_dim=64, total_iters=100000, train_img_dir='data/celeba_hq/train', val_batch_size=32, val_img_dir='data/celeba_hq/val', w_hpf=0.0, weight_decay=0.0001, wing_path='expr/checkpoints/wing.ckpt')\n",
      "Number of parameters of generator: 33892995\n",
      "Number of parameters of mapping_network: 3259072\n",
      "Number of parameters of style_encoder: 20949760\n",
      "Number of parameters of discriminator: 20852803\n",
      "Initializing generator...\n",
      "Initializing mapping_network...\n",
      "Initializing style_encoder...\n",
      "Initializing discriminator...\n",
      "Preparing DataLoader for the generation phase...\n",
      "Preparing DataLoader for the generation phase...\n",
      "Loading checkpoint from expr/checkpoints/afhq/100000_nets_ema.ckpt...\n",
      "Working on expr/results/afhq/reference.jpg...\n",
      "Working on expr/results/afhq/video_ref.mp4...\n",
      "video_ref:  50% 14/28 [04:13<04:35, 19.66s/it]^C\n"
     ]
    }
   ],
   "source": [
    "!python3 main.py --mode sample --num_domains 3 --resume_iter 100000 --w_hpf 0 \\\n",
    "                --checkpoint_dir expr/checkpoints/afhq \\\n",
    "                --result_dir expr/results/afhq \\\n",
    "                --src_dir assets/representative/afhq/src \\\n",
    "                --ref_dir assets/representative/afhq/ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0fiZE15yvgc"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ld-0uIA-yuvU"
   },
   "outputs": [],
   "source": [
    "!python3 main.py --mode eval --num_domains 3 --w_hpf 0 \\\n",
    "                --resume_iter 100000 \\\n",
    "                --train_img_dir data/afhq/train \\\n",
    "                --val_img_dir data/afhq/val \\\n",
    "                --checkpoint_dir expr/checkpoints/afhq \\\n",
    "                --eval_dir expr/eval/afhq"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "stargan-v2-afhq.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
